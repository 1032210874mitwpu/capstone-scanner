import joblib
import pandas as pd
from time import time
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC  # Using LinearSVC instead of SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from preprocess import preprocess_data, vectorize_features

def train_all_models():
    try:
        # 1. SET THE CORRECT CSV PATH
        csv_path = "C:/Users/MRUDULA/capstone/Capstone project/cve.csv"
        print(f"\n[1/6] Checking CSV file at: {csv_path}")
        
        # 2. LOAD AND PREPROCESS DATA
        print("\n[2/6] Loading and preprocessing data...")
        df, label_encoder = preprocess_data(csv_path)
        
        # Take a smaller sample if needed (uncomment if memory issues)
        # df = df.sample(20000, random_state=42)
        
        # 3. VECTORIZE FEATURES
        print("\n[3/6] Vectorizing text features...")
        X, y, tfidf, _ = vectorize_features(df)
        print(f"Features: {X.shape[1]}, Samples: {X.shape[0]}")
        
        # 4. SPLIT DATA
        print("\n[4/6] Splitting into train/test sets...")
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, 
            test_size=0.2,
            random_state=42
        )
        
        # 5. TRAIN MODELS WITH PROGRESS TRACKING
        print("\n[5/6] Training models...")
        
        # Random Forest (faster to train)
        print("\nTraining Random Forest...")
        start_time = time()
        rf = RandomForestClassifier(
            n_estimators=50,  # Reduced number of trees
            max_depth=10,     # Limit tree depth
            n_jobs=-1,       # Use all cores
            random_state=42,
            verbose=1        # Show progress
        )
        rf.fit(X_train, y_train)
        print(f"RF trained in {time()-start_time:.2f}s")
        
        # Linear SVM (faster alternative)
        print("\nTraining Linear SVM...")
        start_time = time()
        svm = LinearSVC(
            dual=False,       # Better for n_samples > n_features
            max_iter=1000,    # Reduced iterations
            random_state=42,
            verbose=1        # Show progress
        )
        svm.fit(X_train, y_train)
        print(f"SVM trained in {time()-start_time:.2f}s")
        
        # Neural Network (smaller network)
        print("\nTraining Neural Network...")
        start_time = time()
        nn = MLPClassifier(
            hidden_layer_sizes=(50,),  # Simpler architecture
            max_iter=100,             # Fewer iterations
            early_stopping=True,      # Stop if no improvement
            random_state=42,
            verbose=True             # Show progress
        )
        nn.fit(X_train, y_train)
        print(f"NN trained in {time()-start_time:.2f}s")
        
        # 6. EVALUATE AND SAVE MODELS
        print("\n[6/6] Evaluating models...")
        for name, model in [('Random Forest', rf), ('SVM', svm), ('Neural Network', nn)]:
            print(f"\n{name} Performance:")
            print(classification_report(y_test, model.predict(X_test)))
        
        # Save models
        print("\nSaving models...")
        joblib.dump(rf, 'models/rf_model.pkl')
        joblib.dump(svm, 'models/svm_model.pkl')
        joblib.dump(nn, 'models/nn_model.pkl')
        joblib.dump(tfidf, 'models/tfidf.pkl')
        joblib.dump(label_encoder, 'models/label_encoder.pkl')
        
        print("\nTraining completed successfully!")
        
    except Exception as e:
        print(f"\nERROR during training: {str(e)}")
        raise

if __name__ == "__main__":
    train_all_models()